{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Cloud Hybrid Infrastructure\n",
                "\n",
                "## Гибридное развертывание: AWS + GCP + On-Premise\n",
                "\n",
                "Этот туториал демонстрирует создание гибридной мульти-облачной инфраструктуры с использованием:\n",
                "\n",
                "- **AWS**: Primary cloud (Frontend, API Gateway)\n",
                "- **GCP**: Secondary cloud (Data Processing, ML Services)\n",
                "- **On-Premise**: Legacy systems, databases\n",
                "- **Tailscale**: Mesh VPN для связи между облаками\n",
                "- **Terraform Workspaces**: Управление окружениями\n",
                "\n",
                "### Архитектура\n",
                "\n",
                "```\n",
                "┌─────────────────────────────────────────────────────┐\n",
                "│                  Tailscale Mesh VPN                 │\n",
                "│              (Secure Cross-Cloud Network)           │\n",
                "└──────────┬──────────────────┬──────────────┬────────┘\n",
                "           │                  │              │\n",
                "    ┌──────▼──────┐   ┌───────▼──────┐  ┌───▼────────┐\n",
                "    │     AWS     │   │     GCP      │  │ On-Premise │\n",
                "    │             │   │              │  │            │\n",
                "    │ - Frontend  │   │ - BigQuery   │  │ - Legacy   │\n",
                "    │ - API GW    │   │ - Dataflow   │  │   DB       │\n",
                "    │ - RDS       │   │ - AI/ML      │  │ - File     │\n",
                "    │ - S3        │   │ - GCS        │  │   Storage  │\n",
                "    └─────────────┘   └──────────────┘  └────────────┘\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 1: Настройка Terraform для Multi-Cloud"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile main.tf\n",
                "\n",
                "terraform {\n",
                "  required_version = \">= 1.5.0\"\n",
                "  \n",
                "  required_providers {\n",
                "    aws = {\n",
                "      source  = \"hashicorp/aws\"\n",
                "      version = \"~> 5.0\"\n",
                "    }\n",
                "    google = {\n",
                "      source  = \"hashicorp/google\"\n",
                "      version = \"~> 5.0\"\n",
                "    }\n",
                "  }\n",
                "  \n",
                "  backend \"s3\" {\n",
                "    bucket         = \"multicloud-terraform-state\"\n",
                "    key            = \"multicloud/terraform.tfstate\"\n",
                "    region         = \"us-east-1\"\n",
                "    encrypt        = true\n",
                "    dynamodb_table = \"terraform-lock\"\n",
                "  }\n",
                "}\n",
                "\n",
                "# AWS Provider\n",
                "provider \"aws\" {\n",
                "  region = var.aws_region\n",
                "  \n",
                "  default_tags {\n",
                "    tags = {\n",
                "      Project     = \"MultiCloud\"\n",
                "      ManagedBy   = \"Terraform\"\n",
                "      Environment = terraform.workspace\n",
                "    }\n",
                "  }\n",
                "}\n",
                "\n",
                "# GCP Provider\n",
                "provider \"google\" {\n",
                "  project = var.gcp_project_id\n",
                "  region  = var.gcp_region\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 2: Создание Tailscale Mesh Network"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile modules/tailscale-mesh/main.tf\n",
                "\n",
                "# AWS Tailscale Node\n",
                "module \"tailscale_aws\" {\n",
                "  source = \"git::https://github.com/v-grand/infra-network.git//modules/tailscale\"\n",
                "\n",
                "  vpc_id            = module.aws_vpc.vpc_id\n",
                "  subnet_id         = module.aws_vpc.private_subnets[0]\n",
                "  tailscale_authkey = var.tailscale_authkey\n",
                "  \n",
                "  instance_type = \"t3.micro\"\n",
                "  \n",
                "  tags = {\n",
                "    Name     = \"tailscale-aws-gateway\"\n",
                "    Cloud    = \"AWS\"\n",
                "    Location = var.aws_region\n",
                "  }\n",
                "  \n",
                "  # Enable subnet routing\n",
                "  advertise_routes = [\n",
                "    module.aws_vpc.vpc_cidr_block\n",
                "  ]\n",
                "}\n",
                "\n",
                "# GCP Tailscale Node\n",
                "resource \"google_compute_instance\" \"tailscale_gcp\" {\n",
                "  name         = \"tailscale-gcp-gateway\"\n",
                "  machine_type = \"e2-micro\"\n",
                "  zone         = \"${var.gcp_region}-a\"\n",
                "\n",
                "  boot_disk {\n",
                "    initialize_params {\n",
                "      image = \"ubuntu-os-cloud/ubuntu-2204-lts\"\n",
                "    }\n",
                "  }\n",
                "\n",
                "  network_interface {\n",
                "    network    = google_compute_network.vpc.name\n",
                "    subnetwork = google_compute_subnetwork.private.name\n",
                "  }\n",
                "\n",
                "  metadata_startup_script = <<-EOF\n",
                "    #!/bin/bash\n",
                "    curl -fsSL https://tailscale.com/install.sh | sh\n",
                "    echo 'net.ipv4.ip_forward = 1' | tee -a /etc/sysctl.conf\n",
                "    sysctl -p\n",
                "    tailscale up --authkey=${var.tailscale_authkey} --advertise-routes=${google_compute_subnetwork.private.ip_cidr_range}\n",
                "  EOF\n",
                "\n",
                "  tags = [\"tailscale\", \"gateway\"]\n",
                "}\n",
                "\n",
                "# On-Premise Tailscale (manual setup instructions)\n",
                "output \"onprem_tailscale_setup\" {\n",
                "  value = <<-EOT\n",
                "    To setup Tailscale on on-premise server:\n",
                "    \n",
                "    1. Install Tailscale:\n",
                "       curl -fsSL https://tailscale.com/install.sh | sh\n",
                "    \n",
                "    2. Enable IP forwarding:\n",
                "       echo 'net.ipv4.ip_forward = 1' | sudo tee -a /etc/sysctl.conf\n",
                "       sudo sysctl -p\n",
                "    \n",
                "    3. Connect to Tailscale:\n",
                "       sudo tailscale up --authkey=${var.tailscale_authkey} --advertise-routes=192.168.1.0/24\n",
                "    \n",
                "    4. Approve routes in Tailscale admin console\n",
                "  EOT\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 3: AWS Infrastructure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile modules/aws/main.tf\n",
                "\n",
                "# VPC\n",
                "module \"aws_vpc\" {\n",
                "  source = \"git::https://github.com/v-grand/infra-network.git//modules/vpc\"\n",
                "\n",
                "  project_name = \"multicloud-aws\"\n",
                "  environment  = terraform.workspace\n",
                "  vpc_cidr     = \"10.0.0.0/16\"\n",
                "\n",
                "  azs             = [\"us-east-1a\", \"us-east-1b\"]\n",
                "  private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n",
                "  public_subnets  = [\"10.0.101.0/24\", \"10.0.102.0/24\"]\n",
                "\n",
                "  enable_nat_gateway = true\n",
                "}\n",
                "\n",
                "# Frontend (S3 + CloudFront)\n",
                "module \"frontend\" {\n",
                "  source = \"git::https://github.com/v-grand/infra-aws.git//modules/s3\"\n",
                "\n",
                "  bucket_name = \"multicloud-frontend-${terraform.workspace}\"\n",
                "  \n",
                "  website_configuration = {\n",
                "    index_document = \"index.html\"\n",
                "    error_document = \"index.html\"\n",
                "  }\n",
                "}\n",
                "\n",
                "# API Gateway (ECS Fargate)\n",
                "module \"api_gateway\" {\n",
                "  source = \"git::https://github.com/v-grand/infra-aws.git//modules/ecs\"\n",
                "\n",
                "  cluster_name    = \"multicloud-api\"\n",
                "  vpc_id          = module.aws_vpc.vpc_id\n",
                "  private_subnets = module.aws_vpc.private_subnets\n",
                "  public_subnets  = module.aws_vpc.public_subnets\n",
                "\n",
                "  services = {\n",
                "    api = {\n",
                "      cpu    = 512\n",
                "      memory = 1024\n",
                "      image  = \"${var.ecr_registry}/api-gateway:latest\"\n",
                "      port   = 8000\n",
                "      \n",
                "      environment = [\n",
                "        {\n",
                "          name  = \"GCP_ENDPOINT\"\n",
                "          value = \"http://100.64.1.10:8080\"  # Tailscale IP\n",
                "        },\n",
                "        {\n",
                "          name  = \"ONPREM_DB\"\n",
                "          value = \"postgresql://100.64.1.20:5432/legacy\"  # Tailscale IP\n",
                "        }\n",
                "      ]\n",
                "    }\n",
                "  }\n",
                "}\n",
                "\n",
                "# RDS Database\n",
                "module \"rds\" {\n",
                "  source = \"git::https://github.com/v-grand/infra-aws.git//modules/rds\"\n",
                "\n",
                "  identifier     = \"multicloud-db\"\n",
                "  engine         = \"postgres\"\n",
                "  engine_version = \"14.7\"\n",
                "  instance_class = \"db.t3.micro\"\n",
                "\n",
                "  vpc_id     = module.aws_vpc.vpc_id\n",
                "  subnet_ids = module.aws_vpc.private_subnets\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 4: GCP Infrastructure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile modules/gcp/main.tf\n",
                "\n",
                "# VPC Network\n",
                "resource \"google_compute_network\" \"vpc\" {\n",
                "  name                    = \"multicloud-gcp-vpc\"\n",
                "  auto_create_subnetworks = false\n",
                "}\n",
                "\n",
                "resource \"google_compute_subnetwork\" \"private\" {\n",
                "  name          = \"private-subnet\"\n",
                "  ip_cidr_range = \"10.1.0.0/16\"\n",
                "  region        = var.gcp_region\n",
                "  network       = google_compute_network.vpc.id\n",
                "}\n",
                "\n",
                "# BigQuery Dataset for Analytics\n",
                "resource \"google_bigquery_dataset\" \"analytics\" {\n",
                "  dataset_id  = \"multicloud_analytics\"\n",
                "  location    = var.gcp_region\n",
                "  description = \"Analytics data from AWS and on-premise\"\n",
                "\n",
                "  access {\n",
                "    role          = \"OWNER\"\n",
                "    user_by_email = var.gcp_service_account_email\n",
                "  }\n",
                "}\n",
                "\n",
                "# Cloud Storage for Data Lake\n",
                "resource \"google_storage_bucket\" \"data_lake\" {\n",
                "  name     = \"multicloud-data-lake-${var.gcp_project_id}\"\n",
                "  location = var.gcp_region\n",
                "\n",
                "  uniform_bucket_level_access = true\n",
                "  \n",
                "  lifecycle_rule {\n",
                "    condition {\n",
                "      age = 90\n",
                "    }\n",
                "    action {\n",
                "      type          = \"SetStorageClass\"\n",
                "      storage_class = \"NEARLINE\"\n",
                "    }\n",
                "  }\n",
                "}\n",
                "\n",
                "# Dataflow Job for Processing\n",
                "resource \"google_dataflow_job\" \"data_processor\" {\n",
                "  name              = \"multicloud-data-processor\"\n",
                "  template_gcs_path = \"gs://dataflow-templates/latest/Word_Count\"\n",
                "  temp_gcs_location = \"gs://${google_storage_bucket.data_lake.name}/temp\"\n",
                "  \n",
                "  parameters = {\n",
                "    inputFile  = \"gs://${google_storage_bucket.data_lake.name}/input/*\"\n",
                "    output     = \"gs://${google_storage_bucket.data_lake.name}/output/\"\n",
                "  }\n",
                "}\n",
                "\n",
                "# Cloud Run for ML API\n",
                "resource \"google_cloud_run_service\" \"ml_api\" {\n",
                "  name     = \"ml-prediction-api\"\n",
                "  location = var.gcp_region\n",
                "\n",
                "  template {\n",
                "    spec {\n",
                "      containers {\n",
                "        image = \"gcr.io/${var.gcp_project_id}/ml-api:latest\"\n",
                "        \n",
                "        env {\n",
                "          name  = \"AWS_DATA_SOURCE\"\n",
                "          value = \"http://100.64.1.5:8000/api/data\"  # Tailscale IP\n",
                "        }\n",
                "      }\n",
                "    }\n",
                "  }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 5: Развертывание инфраструктуры"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Создание workspaces для разных окружений\n",
                "!terraform workspace new production\n",
                "!terraform workspace new staging\n",
                "!terraform workspace new development\n",
                "\n",
                "# Переключение на production\n",
                "!terraform workspace select production\n",
                "\n",
                "# Инициализация\n",
                "!terraform init\n",
                "\n",
                "# План развертывания\n",
                "!terraform plan -out=multicloud.tfplan\n",
                "\n",
                "# Применение (раскомментируйте для реального развертывания)\n",
                "# !terraform apply multicloud.tfplan"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 6: Настройка Data Pipeline между облаками"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile data-pipeline/sync-aws-to-gcp.py\n",
                "\n",
                "import boto3\n",
                "from google.cloud import storage, bigquery\n",
                "import pandas as pd\n",
                "\n",
                "# AWS S3 Client\n",
                "s3 = boto3.client('s3')\n",
                "\n",
                "# GCP Clients\n",
                "gcs_client = storage.Client()\n",
                "bq_client = bigquery.Client()\n",
                "\n",
                "def sync_data_aws_to_gcp():\n",
                "    \"\"\"\n",
                "    Синхронизация данных из AWS S3 в GCP BigQuery\n",
                "    \"\"\"\n",
                "    # 1. Скачать данные из S3\n",
                "    s3_bucket = 'multicloud-data-source'\n",
                "    s3_key = 'exports/daily_data.csv'\n",
                "    \n",
                "    obj = s3.get_object(Bucket=s3_bucket, Key=s3_key)\n",
                "    df = pd.read_csv(obj['Body'])\n",
                "    \n",
                "    # 2. Загрузить в GCS\n",
                "    gcs_bucket = gcs_client.bucket('multicloud-data-lake')\n",
                "    blob = gcs_bucket.blob('staging/daily_data.csv')\n",
                "    blob.upload_from_string(df.to_csv(index=False), content_type='text/csv')\n",
                "    \n",
                "    # 3. Загрузить в BigQuery\n",
                "    table_id = 'multicloud_analytics.daily_metrics'\n",
                "    \n",
                "    job_config = bigquery.LoadJobConfig(\n",
                "        source_format=bigquery.SourceFormat.CSV,\n",
                "        skip_leading_rows=1,\n",
                "        autodetect=True,\n",
                "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND\n",
                "    )\n",
                "    \n",
                "    uri = f\"gs://multicloud-data-lake/staging/daily_data.csv\"\n",
                "    load_job = bq_client.load_table_from_uri(\n",
                "        uri, table_id, job_config=job_config\n",
                "    )\n",
                "    \n",
                "    load_job.result()  # Wait for completion\n",
                "    print(f\"✅ Loaded {load_job.output_rows} rows into {table_id}\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    sync_data_aws_to_gcp()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 7: Мониторинг Multi-Cloud инфраструктуры"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile monitoring/prometheus-config.yml\n",
                "\n",
                "global:\n",
                "  scrape_interval: 15s\n",
                "  evaluation_interval: 15s\n",
                "\n",
                "scrape_configs:\n",
                "  # AWS Metrics (via CloudWatch Exporter)\n",
                "  - job_name: 'aws-cloudwatch'\n",
                "    static_configs:\n",
                "      - targets: ['100.64.1.5:9106']  # Tailscale IP\n",
                "    \n",
                "  # GCP Metrics (via Stackdriver Exporter)\n",
                "  - job_name: 'gcp-stackdriver'\n",
                "    static_configs:\n",
                "      - targets: ['100.64.1.10:9255']  # Tailscale IP\n",
                "  \n",
                "  # On-Premise Metrics\n",
                "  - job_name: 'onprem-node'\n",
                "    static_configs:\n",
                "      - targets: ['100.64.1.20:9100']  # Tailscale IP\n",
                "  \n",
                "  # Tailscale Network Metrics\n",
                "  - job_name: 'tailscale'\n",
                "    static_configs:\n",
                "      - targets: \n",
                "        - '100.64.1.5:9090'   # AWS gateway\n",
                "        - '100.64.1.10:9090'  # GCP gateway\n",
                "        - '100.64.1.20:9090'  # On-prem gateway"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Шаг 8: Тестирование связности"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import requests\n",
                "\n",
                "# Tailscale IPs\n",
                "TAILSCALE_IPS = {\n",
                "    'aws': '100.64.1.5',\n",
                "    'gcp': '100.64.1.10',\n",
                "    'onprem': '100.64.1.20'\n",
                "}\n",
                "\n",
                "def test_connectivity():\n",
                "    \"\"\"Проверка связности между облаками через Tailscale\"\"\"\n",
                "    \n",
                "    print(\"Testing Multi-Cloud Connectivity...\\n\")\n",
                "    \n",
                "    for name, ip in TAILSCALE_IPS.items():\n",
                "        # Ping test\n",
                "        result = subprocess.run(\n",
                "            ['ping', '-c', '3', ip],\n",
                "            capture_output=True,\n",
                "            text=True\n",
                "        )\n",
                "        \n",
                "        if result.returncode == 0:\n",
                "            print(f\"✅ {name.upper()}: Reachable ({ip})\")\n",
                "        else:\n",
                "            print(f\"❌ {name.upper()}: Unreachable ({ip})\")\n",
                "    \n",
                "    # HTTP connectivity test\n",
                "    print(\"\\nTesting HTTP Endpoints...\\n\")\n",
                "    \n",
                "    endpoints = {\n",
                "        'AWS API': f\"http://{TAILSCALE_IPS['aws']}:8000/health\",\n",
                "        'GCP ML API': f\"http://{TAILSCALE_IPS['gcp']}:8080/health\",\n",
                "        'On-Prem DB': f\"http://{TAILSCALE_IPS['onprem']}:5432\"\n",
                "    }\n",
                "    \n",
                "    for name, url in endpoints.items():\n",
                "        try:\n",
                "            response = requests.get(url, timeout=5)\n",
                "            print(f\"✅ {name}: {response.status_code}\")\n",
                "        except Exception as e:\n",
                "            print(f\"❌ {name}: {str(e)}\")\n",
                "\n",
                "test_connectivity()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Заключение\n",
                "\n",
                "### Развернутая Multi-Cloud инфраструктура:\n",
                "\n",
                "✅ **AWS**: Frontend (S3+CloudFront), API Gateway (ECS), Database (RDS)  \n",
                "✅ **GCP**: Data Lake (GCS), Analytics (BigQuery), ML API (Cloud Run)  \n",
                "✅ **On-Premise**: Legacy systems, databases  \n",
                "✅ **Tailscale Mesh VPN**: Безопасная связь между всеми облаками  \n",
                "✅ **Unified Monitoring**: Prometheus + Grafana для всех платформ  \n",
                "✅ **Data Pipeline**: Автоматическая синхронизация данных  \n",
                "\n",
                "### Преимущества Multi-Cloud подхода:\n",
                "\n",
                "1. **Избежание vendor lock-in**\n",
                "2. **Использование лучших сервисов каждого провайдера**\n",
                "3. **Географическая распределенность**\n",
                "4. **Disaster recovery и высокая доступность**\n",
                "5. **Оптимизация затрат**\n",
                "\n",
                "### Следующие шаги:\n",
                "\n",
                "1. Настроить автоматическое failover между облаками\n",
                "2. Добавить Azure в mesh network\n",
                "3. Реализовать cross-cloud backup strategy\n",
                "4. Настроить unified logging (ELK Stack)\n",
                "5. Автоматизировать cost optimization\n",
                "\n",
                "### Полезные команды:\n",
                "\n",
                "```bash\n",
                "# Проверка Tailscale статуса\n",
                "tailscale status\n",
                "\n",
                "# Переключение между workspaces\n",
                "terraform workspace select production\n",
                "\n",
                "# Просмотр ресурсов в AWS\n",
                "terraform state list | grep aws\n",
                "\n",
                "# Просмотр ресурсов в GCP\n",
                "terraform state list | grep google\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}